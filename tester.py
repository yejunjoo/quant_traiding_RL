import yfinance as yf
import gymnasium as gym
import numpy as np
import torch
import matplotlib.pyplot as plt
from datetime import datetime

# ê¸°ì¡´ì— ì‘ì„±í–ˆë˜ ëª¨ë“ˆë“¤ import
from Environment import StockTradingEnv
from algo.ppo import Actor # Actor í´ë˜ìŠ¤ ì •ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤

# ==========================================
# [ì„¤ì •] í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°
# ==========================================
MODEL_PATH = "saved_models/StockTrading_PPO_20251217-023317/actor_epoch_590.pth" # <- ì‹¤ì œ ì €ì¥ëœ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìˆ˜!
TICKER = ["AAPL"] # í•™ìŠµ ë•Œì™€ ë™ì¼í•œ ì¢…ëª©
START_DATE = "2024-01-01"
END_DATE = "2025-01-01" # í˜„ì¬ ì‹œì  (Context ê¸°ì¤€)

# í™˜ê²½ íŒŒë¼ë¯¸í„° (í•™ìŠµ ë•Œì™€ ë™ì¼í•˜ê²Œ)
BANKRUPT_COEF = 0.3
TERMINATION_REWARD = -1e4
MAX_BALANCE = 1e7
# ==========================================

def shape_data_matrix(tickers, start, end):
    print(f"ğŸ“¥ {tickers} ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘ ({start} ~ {end})...")
    # auto_adjust=TrueëŠ” ì¢…ê°€(Close)ê°€ ìˆ˜ì •ì£¼ê°€ë¡œ ë°˜ì˜ë¨
    df = yf.download(tickers, start=start, end=end, auto_adjust=True)

    # [ì¤‘ìš”] ë‹¨ì¼ ì¢…ëª©ì¼ ê²½ìš° MultiIndexê°€ ì•„ë‹ ìˆ˜ ìˆìŒ -> ê°•ì œ ë³€í™˜ í•„ìš” ê°€ëŠ¥ì„± í™•ì¸
    # yfinance ë²„ì „ì— ë”°ë¼ ë‹¤ë¥´ì§€ë§Œ, ë³´í†µ ë‹¨ì¼ ì¢…ëª©ì€ stackì´ í•„ìš” ì—†ìŒ
    if len(tickers) == 1:
        # ë‹¨ì¼ ì¢…ëª©: (Days, Features) -> (Days, 1, Features)ë¡œ ë³€í™˜
        raw_data = df.values
        # Feature ìˆœì„œ íŒŒì•… (ë‚˜ì¤‘ì— Close ê°€ê²© ì°¾ê¸° ìœ„í•´)
        feature_columns = list(df.columns)

        n_days = raw_data.shape[0]
        n_features = raw_data.shape[1]

        # (Days, 1, Features) í˜•íƒœë¡œ Reshape
        data_matrix = raw_data.reshape(n_days, 1, n_features)

    else:
        # ë‹¤ì¤‘ ì¢…ëª©: ê¸°ì¡´ ë¡œì§ ìœ ì§€
        # columnsê°€ (Ticker, Feature) í˜•íƒœì¸ì§€ í™•ì¸ í•„ìš”
        df_stacked = df.stack(level=1, future_stack=True)
        df_stacked = df_stacked.sort_index(level=[0, 1])
        raw_data = df_stacked.values
        feature_columns = list(df_stacked.columns) # ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ (êµ¬ì¡°ì— ë”°ë¼ ë‹¤ë¦„)

        n_days = len(df.index)
        n_features = raw_data.shape[1]
        data_matrix = raw_data.reshape(n_days, len(tickers), n_features)

    print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ. Shape: {data_matrix.shape}")

    # 'Close' ì»¬ëŸ¼ì´ ëª‡ ë²ˆì§¸ ì¸ë±ìŠ¤ì¸ì§€ ì°¾ê¸°
    close_index = 0
    # ë³´í†µ yfinance ì»¬ëŸ¼ì€ ì•ŒíŒŒë²³ ìˆœ: Close, High, Low, Open, Volume
    # auto_adjust=Trueë©´ Adj CloseëŠ” ì—†ìŒ.
    # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ 'Close'ê°€ í¬í•¨ëœ ì»¬ëŸ¼ ì°¾ê¸°
    for i, col in enumerate(df.columns):
        if "Close" in str(col):
            close_index = i
            break

    print(f"â„¹ï¸ Close Price Index: {close_index} (Column: {df.columns[close_index]})")

    return data_matrix, df.index, close_index

def make_env_for_test(data_matrix):
    """
    í•™ìŠµ ë•Œì™€ 'ë˜‘ê°™ì€' ì „ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì¹˜ëŠ” í™˜ê²½ ìƒì„±
    """
    env = StockTradingEnv(df_matrix=data_matrix,
                          bankrupt_coef=BANKRUPT_COEF,
                          termination_reward=TERMINATION_REWARD,
                          max_balance=MAX_BALANCE)

    # Wrapperë„ í•™ìŠµ ë•Œì™€ ë™ì¼í•˜ê²Œ ì”Œì›Œì¤˜ì•¼ ì‹ ê²½ë§ì´ ì…ë ¥ì„ ì´í•´í•¨
    env = gym.wrappers.RecordEpisodeStatistics(env)
    env = gym.wrappers.FlattenObservation(env)
    env = gym.wrappers.NormalizeObservation(env) # ì£¼ì˜: í…ŒìŠ¤íŠ¸ ì‹œì—ëŠ” í†µê³„ì¹˜ê°€ ì´ˆê¸°í™”ëœ ìƒíƒœë¡œ ì‹œì‘í•¨
    env = gym.wrappers.NormalizeReward(env)      # í…ŒìŠ¤íŠ¸ ì‹œ ë³´ìƒ ì •ê·œí™”ëŠ” ê²°ê³¼ í™•ì¸ìš©ìœ¼ë¡œë§Œ ë™ì‘
    env = gym.wrappers.ClipAction(env)

    return env
def test():
    # 1. ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ–¥ï¸ Using device: {device}")

    # 2. ë°ì´í„° ì¤€ë¹„ (close_index ë°›ì•„ì˜¤ê¸° ì¶”ê°€)
    data_matrix, dates, close_idx = shape_data_matrix(TICKER, START_DATE, END_DATE)

    # 3. í™˜ê²½ ìƒì„±
    env = make_env_for_test(data_matrix)
    obs_shape = env.observation_space.shape[0]
    action_shape = env.action_space.shape[0]

    # 4. ëª¨ë¸ ë¡œë“œ
    print(f"ğŸ“‚ ëª¨ë¸ ë¡œë”© ì¤‘: {MODEL_PATH}")
    actor = Actor(obs_dim=obs_shape, action_dim=action_shape).to(device)

    try:
        actor.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        print("âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ!")
    except FileNotFoundError:
        print("âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. MODEL_PATHë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    # 5. í‰ê°€ ëª¨ë“œ
    actor.eval()

    # 6. í…ŒìŠ¤íŠ¸ ë£¨í”„
    obs, info = env.reset()
    done = False

    portfolio_values = []
    rewards = []
    stock_prices = []
    actions_history = []

    print("ğŸš€ ë°±í…ŒìŠ¤íŒ… ì‹œì‘...")

    while not done:
        with torch.no_grad():
            obs_tensor = torch.tensor(obs, dtype=torch.float32).to(device)
            action_tensor = actor(obs_tensor)
            action = action_tensor.cpu().numpy()

        obs, reward, terminated, truncated, info = env.step(action)
        done = terminated or truncated

        # --- [ìˆ˜ì •ëœ ë¶€ë¶„] ë°ì´í„° ìˆ˜ì§‘ ë¡œì§ ---
        raw_env = env.unwrapped

        # (1) ìì‚° ê°€ì¹˜
        if hasattr(raw_env, 'portfolio_value'):
            portfolio_values.append(raw_env.portfolio_value[0] if isinstance(raw_env.portfolio_value, list) else raw_env.portfolio_value)
        else:
            # ê¸°ë³¸ ìì‚° ê³„ì‚° (Environment êµ¬í˜„ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            # raw_env.state[0]ì´ ì”ê³ (balance)ë¼ê³  ê°€ì •í•˜ëŠ” ê²½ìš°ê°€ ë§ìŒ
            portfolio_values.append(MAX_BALANCE)

            # (2) ì£¼ê°€ (ì •í™•í•œ ì¸ë±ì‹±)
        try:
            current_step = raw_env.timestep
            # raw_env.data shape: [Days, Tickers, Features]
            # ìš°ë¦¬ê°€ í•„ìš”í•œ ê²ƒ: [Current Day, 0ë²ˆì§¸ Ticker, Close Feature]
            if current_step < len(raw_env.data):
                # [ìˆ˜ì •] í”¼ì³ ë²¡í„° ì „ì²´([0])ê°€ ì•„ë‹ˆë¼, ê·¸ ì•ˆì˜ close_idxë¥¼ ê°€ì ¸ì˜´
                price = raw_env.data[current_step][0][close_idx]
                stock_prices.append(float(price))
            else:
                stock_prices.append(stock_prices[-1])
        except Exception as e:
            # ë””ë²„ê¹…ì„ ìœ„í•´ ì—ëŸ¬ ì¶œë ¥
            if len(stock_prices) == 0: print(f"Price Error: {e}")
            stock_prices.append(0)

        rewards.append(reward)
        actions_history.append(action[0])

    print("ğŸ ë°±í…ŒìŠ¤íŒ… ì¢…ë£Œ.")

    # (ì´í•˜ ì‹œê°í™” ì½”ë“œëŠ” ë™ì¼)
    # ...
    if len(portfolio_values) > 0:
        initial_value = MAX_BALANCE
        final_value = portfolio_values[-1]
        profit_pct = ((final_value - initial_value) / initial_value) * 100

        print(f"ğŸ’° ì´ˆê¸° ìì‚°: {initial_value:,.0f}")
        print(f"ğŸ’° ìµœì¢… ìì‚°: {final_value:,.0f}")
        print(f"ğŸ“ˆ ìˆ˜ìµë¥ : {profit_pct:.2f}%")

        plt.figure(figsize=(15, 12))

        plt.subplot(4, 1, 1)
        plt.plot(portfolio_values, label='My Portfolio Value', color='red', linewidth=2)
        plt.axhline(y=initial_value, color='gray', linestyle='--', label='Initial Balance')
        plt.title(f'1. Portfolio Performance (Profit: {profit_pct:.2f}%)')
        plt.ylabel('Value (Won/Dollar)')
        plt.legend()
        plt.grid(True)

        plt.subplot(4, 1, 2)
        plt.plot(stock_prices, label=f'{TICKER[0]} Price', color='blue')
        plt.title(f'2. Stock Price Movement ({TICKER[0]})')
        plt.ylabel('Price')
        plt.legend()
        plt.grid(True)

        plt.subplot(4, 1, 3)
        plt.plot(rewards, label='Step Reward', color='purple', alpha=0.7)
        plt.title('3. Rewards per Step')
        plt.ylabel('Reward')
        plt.legend()
        plt.grid(True)

        plt.subplot(4, 1, 4)
        plt.bar(range(len(actions_history)), actions_history, color='green', label='Action (Buy/Sell)', width=1.0)
        plt.title('4. Agent Actions')
        plt.ylabel('Strength')
        plt.legend()
        plt.grid(True)

        plt.tight_layout()
        plt.show()
    else:
        print("âš ï¸ ë°ì´í„°ê°€ ê¸°ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    test()